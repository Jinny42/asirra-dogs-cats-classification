{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "# from imageio import imread\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.join('/', 'mnt', 'sdb2', 'Datasets', 'asirra')\n",
    "trainval_dir = os.path.join(root_dir, 'train')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import asirra as dataset\n",
    "X_trainval, y_trainval = dataset.read_asirra_subset(trainval_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_size = int(trainval_size * 0.2)    # FIXME\n",
    "\n",
    "train_set = dataset.DataSet(X_trainval[:val_size], y_trainval[:val_size])\n",
    "val_set = dataset.DataSet(X_trainval[val_size:], y_trainval[val_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.images.shape)\n",
    "print(train_set.images.min(), train_set.images.max())\n",
    "print(val_set.images.shape)\n",
    "print(val_set.images.min(), val_set.images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_set.labels[:, 1] == 0).sum(), (train_set.labels[:, 1] == 1).sum())\n",
    "print((val_set.labels[:, 1] == 0).sum(), (val_set.labels[:, 1] == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preliminary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_d = dict()\n",
    "# Mean image\n",
    "hp_d['image_mean'] = train_set.images.mean(axis=(0, 1, 2))\n",
    "print(hp_d['image_mean'])\n",
    "print((train_set.images - hp_d['image_mean']).mean(axis=(0, 1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIXME: Regularization hyperparameters\n",
    "hp_d['weight_decay'] = 0.0005\n",
    "hp_d['dropout_prob'] = 0.5\n",
    "\n",
    "# FIXME: Training hyperparameters\n",
    "hp_d['batch_size'] = 256\n",
    "hp_d['num_epochs'] = 200\n",
    "\n",
    "hp_d['augment_train'] = True \n",
    "hp_d['augment_pred'] = True \n",
    "\n",
    "hp_d['init_learning_rate'] = 0.01\n",
    "hp_d['momentum'] = 0.9\n",
    "hp_d['learning_rate_patience'] = 30\n",
    "hp_d['learning_rate_decay'] = 0.1\n",
    "hp_d['eps'] = 1e-8\n",
    "\n",
    "# FIXME: Evaluation hyperparameters\n",
    "hp_d['score_threshold'] = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models.nn import AlexNet as ConvNet\n",
    "from learning.optimizers import MomentumOptimizer as Optimizer\n",
    "from learning.evaluators import AccuracyEvaluator as Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)\n",
    "\n",
    "model = ConvNet([227, 227, 3], 2, **hp_d)\n",
    "evaluator = Evaluator()\n",
    "optimizer = Optimizer(model, train_set, evaluator, val_set=val_set, **hp_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(-np.log(0.5))\n",
    "train_results = optimizer.train(sess, details=True, verbose=True, **hp_d)    # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
